{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2015, 2016 [Sebastian Raschka](sebastianraschka.com)\n",
    "\n",
    "https://github.com/rasbt/python-machine-learning-book\n",
    "\n",
    "[MIT License](https://github.com/rasbt/python-machine-learning-book/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 - Predicting Continuous Target Variables with Regression Analysis (회귀분석에 의한 연속형 목표변수 예측) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Sebastian Raschka\" -u -d -v -p numpy,pandas,matplotlib,sklearn,seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Introducing a simple linear regression model](#Introducing-a-simple-linear-regression-model2)\n",
    "- [Exploring the Housing Dataset](#Exploring-the-Housing-Dataset)\n",
    "  - [Visualizing the important characteristics of a dataset](#Visualizing-the-important-characteristics-of-a-dataset)\n",
    "- [Implementing an ordinary least squares linear regression model](#Implementing-an-ordinary-least-squares-linear-regression-model)\n",
    "  - [Solving regression for regression parameters with gradient descent](#Solving-regression-for-regression-parameters-with-gradient-descent)\n",
    "  - [Estimating the coefficient of a regression model via scikit-learn](#Estimating-the-coefficient-of-a-regression-model-via-scikit-learn)\n",
    "- [Fitting a robust regression model using RANSAC](#Fitting-a-robust-regression-model-using-RANSAC)\n",
    "- [Evaluating the performance of linear regression models](#Evaluating-the-performance-of-linear-regression-models)\n",
    "- [Using regularized methods for regression](#Using-regularized-methods-for-regression)\n",
    "- [Turning a linear regression model into a curve - polynomial regression](#Turning-a-linear-regression-model-into-a-curve---polynomial-regression)\n",
    "  - [Modeling nonlinear relationships in the Housing Dataset](#Modeling-nonlinear-relationships-in-the-Housing-Dataset)\n",
    "  - [Dealing with nonlinear relationships using random forests](#Dealing-with-nonlinear-relationships-using-random-forests)\n",
    "    - [Decision tree regression](#Decision-tree-regression)\n",
    "    - [Random forest regression](#Random-forest-regression)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 탐색과 시각화 \n",
    "- 선형회귀 모델의 구현을 위한 여러가지 방법 살펴보기 \n",
    "- 이상치에 강건한 회귀 모델 훈련하기 \n",
    "- 회귀 모델 평가와 일반적인 문제 진단 \n",
    "- 비선형 데이터에 회귀 모델 피팅하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 심플 선형회귀 모델 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심플(단변량, univariate) 선형회귀의 목표는 단일 피처(설명변수 $x$)와 연속형 반응 값(목표변수 $y$) 간의 관계를 모델링하는 것이다. \n",
    "우리의 목표는 설명변수와 목표변수 간의 관계를 설명하기 위해 선형방정식의 가중치를 학습하여 훈련 데이터의 일부가 아니었던 새로운 설명변수의 반응을 예측하는 데 사용하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./images/10_01.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적-피팅 직선 역시 회귀선이라고 하며, 회귀선에서 샘플 관측치들까지의 수직선을 오프셋(offsets) 또는 잔차(residuals)라고 부른다(예측에 대한 오차). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1978년에 해리슨 박사(D.Harrison)와 L.루빈펠트 박사(D.L.Rubinfeld)가 수집한 보스턴 외곽 집들에 대한 정보를 포함하고 있다. \n",
    "\n",
    "Source: [https://archive.ics.uci.edu/ml/datasets/Housing](https://archive.ics.uci.edu/ml/datasets/Housing)\n",
    "\n",
    "Attributes:\n",
    "    \n",
    "<pre>\n",
    "1. CRIM      per capita crime rate by town \n",
    "             자치시별 1인당 범죄율\n",
    "2. ZN        proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "             25,000평방피트를 초과하는 거주지역의 비율\n",
    "3. INDUS     proportion of non-retail business acres per town \n",
    "             비소매상업지역이 점유하고 있는 토지의 비율 \n",
    "4. CHAS      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "             찰스강에 대한 더미 변수(강의 경계 위치이면 1, 아니면 0)\n",
    "5. NOX       nitric oxides concentration (parts per 10 million) \n",
    "             10ppm당 일산화질산 농도 \n",
    "6. RM        average number of rooms per dwelling \n",
    "             주택 1가구당 평균 방의 개수 \n",
    "7. AGE       proportion of owner-occupied units built prior to 1940 \n",
    "             1940년 이전에 걱축된 소유 주택의 비율 \n",
    "8. DIS       weighted distances to five Boston employment centres \n",
    "             5개 보스턴 직업센터까지의 접근성 \n",
    "9. RAD       index of accessibility to radial highways \n",
    "             방사형 고속도로까지의 접근성에 대한 지표 \n",
    "10. TAX      full-value property-tax rate per $10,000 \n",
    "             10,000달더당 재산세율 \n",
    "11. PTRATIO  pupil-teacher ratio by town\n",
    "             자치시별 학생/교사 비율 \n",
    "12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "             여기서 Bk는 자치시별 흑인 비율 \n",
    "13. LSTAT    % lower status of the population \n",
    "             모집단의 하위계층의 비율(%) \n",
    "14. MEDV     Median value of owner-occupied homes in $1000's \n",
    "             본인 소유의 주택가격(중앙값) (단위: 1,000달러) \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                 'housing/housing.data',\n",
    "                 header=None,\n",
    "                 sep='\\s+')\n",
    "\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', \n",
    "              'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Note:\n",
    "\n",
    "\n",
    "If the link to the Housing dataset provided above does not work for you, you can find a local copy in this repository at [./../datasets/housing/housing.data](./../datasets/housing/housing.data).\n",
    "\n",
    "Or you could fetch it via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/datasets/housing/housing.data',\n",
    "                  header=None, sep='\\s+')\n",
    "\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', \n",
    "              'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the important characteristics of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "cols = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']\n",
    "\n",
    "sns.pairplot(df[cols], size=2.5)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/scatter.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피처 간 선형관계를 수량화하기 위해 이제 상관행렬을 생성하려고 한다. \n",
    "직관적으로 상관행렬은 공분산행렬이 재조정된 버전으로 이해할 수 있다. \n",
    "사실, 상관행렬은 표준화 데이터로 계산한 공분산행렬과 같다. \n",
    "\n",
    "상관행렬은 피어슨곱-모멘트 상관계수(Person product-moment correlation coefficients, Pearson's으로 표기되기도 함)를 포함하는 제곱행렬이다. \n",
    "이것은 피처쌍 간의 선형 의존성을 측정한다. \n",
    "상관계수는 -1과 1 사이의 범위에 존재한다. \n",
    "\n",
    "$r$=1 이면 두 피처는 완전한 양의 상관관계를 갖는 것이며, $r$=-1이면 두 피처는 완전한 음의 상관관계를 갖는 것이다. \n",
    "피어슨 상관계수는 두 피처 $x$와 $y$ 간의 공분산(분자)을 $x$와 $y$의 표준편자의 곱(분모)으로 나눔으로써 계산할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='./images/10_21.png', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $\\mu$는 피처에 대한 샘플 평균, $\\sigma_{xy}$은 피처 $x$와 $y$ 간의 공분산, 그리고 $\\sigma_x$와 $\\sigma_y$는 각각 피처의 표준편차를 가리킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cm,\n",
    "                 cbar=True,\n",
    "                 annot=True,\n",
    "                 square=True,\n",
    "                 fmt='.2f',\n",
    "                 annot_kws={'size': 15},\n",
    "                 yticklabels=cols,\n",
    "                 xticklabels=cols)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./figures/corr_mat.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an ordinary least squares linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Solving regression for regression parameters with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD(object):\n",
    "\n",
    "    def __init__(self, eta=0.001, n_iter=20):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.net_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['RM']].values\n",
    "y = df['MEDV'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_std = sc_x.fit_transform(X)\n",
    "y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegressionGD()\n",
    "lr.fit(X_std, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, lr.n_iter+1), lr.cost_)\n",
    "plt.ylabel('SSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/cost.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regplot(X, y, model):\n",
    "    plt.scatter(X, y, c='lightblue')\n",
    "    plt.plot(X, model.predict(X), color='red', linewidth=2)    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X_std, y_std, lr)\n",
    "plt.xlabel('Average number of rooms [RM] (standardized)')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV] (standardized)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/gradient_fit.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope: %.3f' % lr.w_[1])\n",
    "print('Intercept: %.3f' % lr.w_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rooms_std = sc_x.transform(np.array([[5.0]]))\n",
    "price_std = lr.predict(num_rooms_std)\n",
    "print(\"Price in $1000's: %.3f\" % sc_y.inverse_transform(price_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the coefficient of a regression model via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression()\n",
    "slr.fit(X, y)\n",
    "y_pred = slr.predict(X)\n",
    "print('Slope: %.3f' % slr.coef_[0])\n",
    "print('Intercept: %.3f' % slr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X, y, slr)\n",
    "plt.xlabel('Average number of rooms [RM]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/scikit_lr_fit.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal Equations** alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column vector of \"ones\"\n",
    "Xb = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "w = np.zeros(X.shape[1])\n",
    "z = np.linalg.inv(np.dot(Xb.T, Xb))\n",
    "w = np.dot(z, np.dot(Xb.T, y))\n",
    "\n",
    "print('Slope: %.3f' % w[1])\n",
    "print('Intercept: %.3f' % w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fitting a robust regression model using RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    ransac = RANSACRegressor(LinearRegression(), \n",
    "                             max_trials=100, \n",
    "                             min_samples=50, \n",
    "                             residual_metric=lambda x: np.sum(np.abs(x), axis=1), \n",
    "                             residual_threshold=5.0, \n",
    "                             random_state=0)\n",
    "else:\n",
    "    ransac = RANSACRegressor(LinearRegression(), \n",
    "                             max_trials=100, \n",
    "                             min_samples=50, \n",
    "                             loss='absolute_loss', \n",
    "                             residual_threshold=5.0, \n",
    "                             random_state=0)\n",
    "\n",
    "\n",
    "ransac.fit(X, y)\n",
    "inlier_mask = ransac.inlier_mask_\n",
    "outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "line_X = np.arange(3, 10, 1)\n",
    "line_y_ransac = ransac.predict(line_X[:, np.newaxis])\n",
    "plt.scatter(X[inlier_mask], y[inlier_mask],\n",
    "            c='blue', marker='o', label='Inliers')\n",
    "plt.scatter(X[outlier_mask], y[outlier_mask],\n",
    "            c='lightgreen', marker='s', label='Outliers')\n",
    "plt.plot(line_X, line_y_ransac, color='red')   \n",
    "plt.xlabel('Average number of rooms [RM]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/ransac_fit.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope: %.3f' % ransac.estimator_.coef_[0])\n",
    "print('Intercept: %.3f' % ransac.estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the performance of linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression()\n",
    "\n",
    "slr.fit(X_train, y_train)\n",
    "y_train_pred = slr.predict(X_train)\n",
    "y_test_pred = slr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train_pred,  y_train_pred - y_train,\n",
    "            c='blue', marker='o', label='Training data')\n",
    "plt.scatter(y_test_pred,  y_test_pred - y_test,\n",
    "            c='lightgreen', marker='s', label='Test data')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\n",
    "plt.xlim([-10, 50])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('./figures/slr_residuals.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regularized methods for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning a linear regression model into a curve - polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([258.0, 270.0, 294.0, \n",
    "              320.0, 342.0, 368.0, \n",
    "              396.0, 446.0, 480.0, 586.0])[:, np.newaxis]\n",
    "\n",
    "y = np.array([236.4, 234.4, 252.8, \n",
    "              298.6, 314.2, 342.2, \n",
    "              360.8, 368.0, 391.2,\n",
    "              390.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "lr = LinearRegression()\n",
    "pr = LinearRegression()\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "X_quad = quadratic.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear features\n",
    "lr.fit(X, y)\n",
    "X_fit = np.arange(250, 600, 10)[:, np.newaxis]\n",
    "y_lin_fit = lr.predict(X_fit)\n",
    "\n",
    "# fit quadratic features\n",
    "pr.fit(X_quad, y)\n",
    "y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X, y, label='training points')\n",
    "plt.plot(X_fit, y_lin_fit, label='linear fit', linestyle='--')\n",
    "plt.plot(X_fit, y_quad_fit, label='quadratic fit')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/poly_example.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin_pred = lr.predict(X)\n",
    "y_quad_pred = pr.predict(X_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training MSE linear: %.3f, quadratic: %.3f' % (\n",
    "        mean_squared_error(y, y_lin_pred),\n",
    "        mean_squared_error(y, y_quad_pred)))\n",
    "print('Training R^2 linear: %.3f, quadratic: %.3f' % (\n",
    "        r2_score(y, y_lin_pred),\n",
    "        r2_score(y, y_quad_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling nonlinear relationships in the Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LSTAT']].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "# create quadratic features\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "cubic = PolynomialFeatures(degree=3)\n",
    "X_quad = quadratic.fit_transform(X)\n",
    "X_cubic = cubic.fit_transform(X)\n",
    "\n",
    "# fit features\n",
    "X_fit = np.arange(X.min(), X.max(), 1)[:, np.newaxis]\n",
    "\n",
    "regr = regr.fit(X, y)\n",
    "y_lin_fit = regr.predict(X_fit)\n",
    "linear_r2 = r2_score(y, regr.predict(X))\n",
    "\n",
    "regr = regr.fit(X_quad, y)\n",
    "y_quad_fit = regr.predict(quadratic.fit_transform(X_fit))\n",
    "quadratic_r2 = r2_score(y, regr.predict(X_quad))\n",
    "\n",
    "regr = regr.fit(X_cubic, y)\n",
    "y_cubic_fit = regr.predict(cubic.fit_transform(X_fit))\n",
    "cubic_r2 = r2_score(y, regr.predict(X_cubic))\n",
    "\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X, y, label='training points', color='lightgray')\n",
    "\n",
    "plt.plot(X_fit, y_lin_fit, \n",
    "         label='linear (d=1), $R^2=%.2f$' % linear_r2, \n",
    "         color='blue', \n",
    "         lw=2, \n",
    "         linestyle=':')\n",
    "\n",
    "plt.plot(X_fit, y_quad_fit, \n",
    "         label='quadratic (d=2), $R^2=%.2f$' % quadratic_r2,\n",
    "         color='red', \n",
    "         lw=2,\n",
    "         linestyle='-')\n",
    "\n",
    "plt.plot(X_fit, y_cubic_fit, \n",
    "         label='cubic (d=3), $R^2=%.2f$' % cubic_r2,\n",
    "         color='green', \n",
    "         lw=2, \n",
    "         linestyle='--')\n",
    "\n",
    "plt.xlabel('% lower status of the population [LSTAT]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/polyhouse_example.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['LSTAT']].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "# transform features\n",
    "X_log = np.log(X)\n",
    "y_sqrt = np.sqrt(y)\n",
    "\n",
    "# fit features\n",
    "X_fit = np.arange(X_log.min()-1, X_log.max()+1, 1)[:, np.newaxis]\n",
    "\n",
    "regr = regr.fit(X_log, y_sqrt)\n",
    "y_lin_fit = regr.predict(X_fit)\n",
    "linear_r2 = r2_score(y_sqrt, regr.predict(X_log))\n",
    "\n",
    "# plot results\n",
    "plt.scatter(X_log, y_sqrt, label='training points', color='lightgray')\n",
    "\n",
    "plt.plot(X_fit, y_lin_fit, \n",
    "         label='linear (d=1), $R^2=%.2f$' % linear_r2, \n",
    "         color='blue', \n",
    "         lw=2)\n",
    "\n",
    "plt.xlabel('log(% lower status of the population [LSTAT])')\n",
    "plt.ylabel('$\\sqrt{Price \\; in \\; \\$1000\\'s [MEDV]}$')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/transform_example.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with nonlinear relationships using random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X = df[['LSTAT']].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "sort_idx = X.flatten().argsort()\n",
    "\n",
    "lin_regplot(X[sort_idx], y[sort_idx], tree)\n",
    "plt.xlabel('% lower status of the population [LSTAT]')\n",
    "plt.ylabel('Price in $1000\\'s [MEDV]')\n",
    "# plt.savefig('./figures/tree_regression.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df['MEDV'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=1000, \n",
    "                               criterion='mse', \n",
    "                               random_state=1, \n",
    "                               n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train_pred,  \n",
    "            y_train_pred - y_train, \n",
    "            c='black', \n",
    "            marker='o', \n",
    "            s=35,\n",
    "            alpha=0.5,\n",
    "            label='Training data')\n",
    "plt.scatter(y_test_pred,  \n",
    "            y_test_pred - y_test, \n",
    "            c='lightgreen', \n",
    "            marker='s', \n",
    "            s=35,\n",
    "            alpha=0.7,\n",
    "            label='Test data')\n",
    "\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\n",
    "plt.xlim([-10, 50])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('./figures/slr_residuals.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
